\documentclass{article}
\usepackage{courier}
\renewcommand{\ttdefault}{pcr}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{caption}
\usepackage{enumerate}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{algorithm,algorithmic}
\newcounter{ALC@tempcntr}% Temporary counter for storage
\newcommand{\LCOMMENT}[1]{%
    \setcounter{ALC@tempcntr}{\arabic{ALC@rem}}% Store old counter
    \setcounter{ALC@rem}{1}% To avoid printing line number
    \item \{#1\}% Display comment + does not increment list item counter
    \setcounter{ALC@rem}{\arabic{ALC@tempcntr}}% Restore old counter
}%
\usepackage{booktabs}

\begin{document}
\title{Data Integration on High-Difficulty Binary Classification}
\author{Julia Finch, Jesse Hellemn, Kentaro Hoffman, Zhe Zhang}
\maketitle


\section{Abstract}


\section{Introduction}
For classification tasks in many fields, especially in medicine and the social
sciences, it is increasingly common for data to come from multiple disparate
data sources. For example, a sociologist might be interested in predicting
future income using two different sources, one on family environment and one on
school environment (we will use "source" to refer to a single coherent
dataset). For the best analysis and classification results, all data sources
should be taken into account. However, most current machine learning
classification techniques have been developed for only single dataset inputs,
and it is not obvious how to best adapt these techniques to multi-source data.

A naive approach is to concatenate the sources together into one large feature
matrix, essentially treating all of the data as a single incoherent source.
Although simple and computationally efficient, this method throws away
information about the separate sources and forces data analysis and
classification techniques to treat all of the sources in the same way. Various
data integration techniques have been proposed to more cleverly and effectively
combine multiple sources. Unfortunately, these techniques have been poorly
tested, and there has been no systematic evaluation of their effectiveness.

This paper evaluates one such specialized data integration techniques,
Generalized Metric Kernel Learning (GMKL), against traditional classifiers that
use concatenated data. We simulate many multi-source datasets with a variety of
properties for these comparative tests. We will use the term "classifier" to
refer to both specialized data integration techniques such as GMKL as well as
naive methods that first concatenate all sources together.


\section{Data Generation}

\subsection{Criteria of Good Simulated Data}

In order to understand the behavior of the classifiers as properties of
multi-source data are varied, we systematically created data to satisfy all of
the criteria in \ref{tab:criteria}.  These criteria allow us to test all the
classifiers fairly against each other on consistent benchmarks.

\begin{minipage}{\textwidth}
\centering
\begin{enumerate}
    \item The dataset consists of two separate sources.
    \item \label{itm:separable} the two classes are separated by a true
        decision boundary that is known and calculable
    \begin{itemize}
        \item or the two classes can be specified to overlap with percentage
            $p$, where $p=0$ leads to no overlap and $p=50$\% leads to complete
            overlap
    \end{itemize}
    \item the decision boundary's complexity (and thus difficulty) can be
        parametrized and controlled
    \item the reliability of each source can be specified exactly
    \item the noisyness of each source can be specified exactly
    \begin{itemize}
        \item \label{itm:noise_dims} extra meaningless dimensions can be
            added to each source
    \end{itemize}
\end{enumerate}
\captionof{table}{Criteria of Simulated Data}
\label{tab:criteria}
\end{minipage}

\subsubsection{Explanation for Data Criteria}

Suppose that a classifier $C$ only obtains 60\% classification accuracy on a
dataset $D$ (with datapoints evenly split amongst 2 classes). This could be
attributable to either:
\begin{itemize}
    \item The classifier is not well suited to certain properties of dataset $D$
    \item 80\% of both classes overlap with each other. The best possible
        strategy in this area of overlap is to guess the class with 50\%
        accuracy. An optimal classifier will then guess 40\% of the datapoints
        correctly and also classify the 20\% of non-overlapping datapoints
        perfectly
\end{itemize}
Criterion \ref{itm:separable} ensures that the latter case does not occur,
so that classifier performance is attributable solely to its efficacy on
certain types of data.

Criteria \ref{itm:noisey} is more difficult than it at first seems. In
order to create a source with $N_{useful}$ useful dimensions and $N_{noisy}$
meaningless dimensions, we needed to both 1) make $N_{noisy}$ dimensions of
pure noise and 2) make $N_{useful}$ dimensions, all of which are always useful.
With a random coefficient linear model, it is impossible to verify that all
$N_{useful}$ dimensions are actually useful.



\subsection{Data Generation Models}

\subsubsection{Random Coefficient Linear Model}

A simple, common way to simulate data is to use a linear model with random
coefficients. This model generates data by:
\begin{enumerate}
    \item Specify the number of true latent variables $K$ along with the number
        of visible variables $N$
    \item Specify two distribution $D_j^0$ and $D_j^1$ of each latent variable
        $z_j$, $1 \leq j \leq K$, where $D_j^0$ is the distribution of $z_j$
        for negative classes and $D_j^1$ is the distribution of $z_j$ for
        positive classes
    \item Specify how each visible variable $x_j$ is generated from the latent
        variables $z_i$ with a formula of the form
        $$
        x_l
        = \sum_{i=1}^K \beta_i z_i
        + \sum_{i=1}^K\sum_{j=i}^K \beta_{i,j} z_i z_k
        + \text{higher-order-interactions}
        $$
        of linear combinations of arbitrary functions of the latent variables
    \item Specify every $\beta$ in the above formula
    \item For every datapoint
    \begin{enumerate}
        \item Pick which class the datapoint belongs to
        \item Sample each $z_j$ from its respective distribution for this class
        \item Generate each visible variable $x_j$ from its formula
    \end{enumerate}
\end{enumerate}

This model has significant shortcomings
\begin{itemize}
    \item It is not known how to systematically make the classification problem
        more or less difficult
    \item It is hard to know if the generated data overlaps
    \item It is hard to pick the $\beta$s to ensure that all of the criteria in
        \ref{table:critera} are satisfied
    \item There are many distributions and formulas to specify arbitrarily
    \item It is hard to know how many of the generated dimensions are useful
\end{itemize}


\subsubsection{Feed-forward Network Model}

In order to satisfy all of the critera in \ref{tab:criteria}, we created a
feed-forward conditional network (figure \ref{fig:data_generation_model.png}).
This network's process is given in Algorithm \ref{alg:network_model}.

\begin{algorithm}
\centering
\begin{algorithmic}[1]
    \label{alg:network_model}
    \caption{The network model}
    \LCOMMENT{Sample the $y$ layer}
    \STATE $y \leftarrow$ Bernoulli($p$)
    \LCOMMENT{Sample the $z$ layer}
    \FORALL{$z_i \in \{z_1, z_2\}$}
        \STATE $c \leftarrow$ Bernoulli($p_i$) \COMMENT{$p_i$ chance to corrupt
            source $i$}
        \STATE $z_i \leftarrow c * (1-y) + (1-c) * y$ \COMMENT{If corrupting,
            $z_i$ will be 0 if $y$ is 1 and 1 if $y$ is 0}
    \ENDFOR
    \LCOMMENT{Sample the $x$ layer of source 1, an $N_1$-dimensional XOR}
    \IF{$z_1$ is even}
        \STATE $x^{(1)}_1 ... x^{(1)}_{N_1} \leftarrow N_1$-dimensional binary
        vector of even parity
    \ELSE
        \STATE $x^{(1)}_1 ... x^{(1)}_{N_1} \leftarrow N_1$-dimensional binary
        vector of odd parity
    \ENDIF
    \LCOMMENT{Sample the $x$ layer of source 2, a $k_2$-period sine wave}
    \STATE $x^{(2)}_1 \leftarrow $ Uniform($-k_2\pi$, $k_2\pi$)
    \STATE $x^{(2)}_2 \leftarrow $ Uniform($-k_2\pi$, $k_2\pi$)
    \STATE $x^{(2)}_3 \leftarrow (x^{(2)}_1+x^{(2)}_2)sine(x^{(2)}_1) + mz_2$
\end{algorithmic}
\end{algorithm}

The above model creates two sources of data with very different types of
decision boundaries.

The first source consists of clusters of points at every
corner of an $N$-dimensional hypercube, where each corner belongs to a
different class than all of its $N-1$ closest neighboring corners (figure
\ref{fig:xor}). The complexity of the decision boundary is proportional to the
dimension.

The second source is a sine wave in 3D space (figure \ref{fig:sine_wave}); the
complexity of this decision boundary is directly proportional to the period of
the wave and inversely proportional to the margin $m$ between the two classes.

\begin{figure}
\begin{minipage}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{xor_3d_square.png}
    \caption{A 3D-XOR with equal class size and $\sigma=0.2$ noise.}
    \label{fig:xor}
\end{minipage}
\begin{minipage}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{sine_wave_square.png}
    \caption{The 3 period sine wave created as the second source by the network
        example in \ref{fig:network}, with $\sigma=0$ noise and a margin of
        $m=10$}
    \label{fig:sine_wave}
\end{minipage}
\end{figure}

This model has several nice properties:
\begin{itemize}
    \item For both the $N$-dimensional XOR and the sine wave (with small enough
        margin $m$), every dimension is necessary for perfect classification.
    \item The reliability of each source can be varied independently of the
        other.
    \item The data can be made more noisy (to an extent) without
        compromising the separability of the two classes.
    \item Extra meaningless dimensions can easily be added to either source.
\end{itemize}






\section{Experiments}

\subsection{Experiment 1: Data Dimension Scaling}
With the prevalence of high dimensional data sets, we first would like to see
if our data integration methods scale well as the dimension of the data sources
increases. To this end, we generated several data sets of varying number of
$N_{useful}$ dimensions from a double-XOR feed-forward network. The network is
structured such that each data source receives the parity signal without
corruption from the true source, y. Then it creates an arbitrary n-dimensional
XOR of correct parity, which then becomes a 2n dimensional data vector.  A full
set of paramters for this expierment can be seen in table 4.1. This network was
chosen as it has no corruption of data sources, thus ensuring criteria 1.
Second, as the dimensional of the XOR increases, the decision boundary becomes
increasingly complicated. Once the data generation process is complete,
classification was done by GMKL, Concatenate + GMKL, SVM, KNN, and Random
Forest.
\begin{table}[h!]
\centering
 \begin{tabular}{|c c|} 
 \hline
Parameter & Value \\ 
\hline
Type of Data from each Data Source & [XOR, XOR]\\
$N_{useful}$ (For each data source) & [2,3,4,5,6,7] \\
$N_{noisey}$& 0\\
Number of Total Data points & 5000\\
Ratio of Training to Testing Data & 1:2\\
Probability of Data Source Signal Corruption & [0,0]\\
I must be missing some more parameters\\
\hline
 \end{tabular}
\end{table}
\textbf{These paramters values should be replaced with the correct variable names once section 2.2.2 is completed. }\\\
\textbf{Should the parameters for the classifiers be described here? or in an appendix? Or in the methods section? }
\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.4]{experimentpic1.png}
\end{center}
\end{figure}


From figure \textbf{FIGURE NUMBER HERE}  we can see that as number of XOR dimensions increases, the classification accuracy of all of the classifiers decreases. This makes sense as the dimensionality of the data is increased without a corresponding increase in the number of data points, making the classifiers suffer from the curse of dimensionality. However, while all classifiers have decreasing accuracy, we can see that GMKL performs much better than the other classifiers with nearly a 35 percent better classification accuracy compared to the classical SVM at at 5 dimensions. In fact, there is a very intriguing pattern on display here as the the GMKL at 2n dimensions seems to be performing about as well as the classical SVM at n dimensions. This seems to indicate that maybe doing classification on the data sources as separate entities is highly desirabel for complicated classification problems. 

\begin{figure}
\begin{center}
\begin{tabular}{|c| c| c| c| c| }
\hline
GMKL Dimension & Accuracy & SVM Dimension & Accuracy & Difference\\
\hline
2 & a & 4 & a\\
\hline
3 & a & 6 &a
\end{tabular}
\end{center}
\end{figure}

\begin{figure}[h]
\includegraphics[scale=0.6]{experimentpic2.png}
\includegraphics[scale=0.6]{experimentpic3.png}
\caption{test}
\end{figure}









\subsection{Experiment 2: Corrupted Sources}

One variable that we decided to vary is the relative importance of the disparate sources. The purpose of this experiement is to evaluate how the various classifiers perform when one source is more important than the other. We want to see which classifers are able to identify the important sources/features.

In order to corrupt the sources, a Bernoulli experiemnt is performed for each source with a certain probability that the binomial indicator is flipped to 0 or 1 (whichever number it is currently not). A probability $p_1$ is assigned to the first source and a probability$ p_2$ is assigned to the second source. These probabilities rnage from 0, meaning no corruption, to .5, meaning complete corruption. For example, say the true value of y is 0, $p_1$ is 0, and $p_2$ is 0.5. Then the data that stems from the first source accurately represents the value of y which is 0. The data that stems from the second source will accurately represent the value of y in 50 percent of the samples, but the other 50 percent of the samples it flips to represent 1. This means that all of the information is coming from the first source while the second source tells us nothing about the true value of y.

In order to test how the classifiers perform with different level of corruption on the Double XOR data, we varied the probability of corruption for each XOR source in increments of 0.1 from 0 to 0.5. We performed this experiment three times, holding the dimension of each source static at three, five, and seven. The results of this experiement performed on five dimensional XOR are displayed in the table below. See the appendix for the results from the three dimensional and seven dimensional experiements.

*insert table here *
*insert heatmaps here*

We see that the results of Experiment 2 are consistent with the results of Experiment 1 in that GMKL consistenetly outperforms concatenated GMKL which consistenly outperforms the standard classifiers. We also see that GMKL is the least affected by one of the two sources becoming corrupted. This is evidence that GMKL effectively identifies which sources are useful and relies primarily on those sources.


\section{Conclusion}
From these experiment we have seen not only the usefulness of GMKL, but also with the issues that traditional classifiers face in data integration. Higher dimensional data, corrupted data sources, noisy dimensions, and variably useful data sources have all been shown to negatively effect the classification accuracy of traditional classifiers such as KNN, SVM and random forest. Not only does this illustrate the usefulness of GMKL as tool for classification and data integration, but the way in which GMKL generates kernels separately seems to indicate the important of treating your data sources as separate entities and the damage you will do to your classification accuracy if you concatenate it all together without any thought.


\section{Future Work}
For future work, first, we would like to see GMKL used on an real life data analysis problem too see if it shows the same utility that we saw previously. Second, since GMKL, and the creation of kernels is a fairly expensive operation to begin with, it would be nice to create a computationally less expensive version so that this could be run on larger datasets. Third, to show that GMKL is indeed up to the performance of other cutting edge algorithm, further comparison with other methods such as Neural Networks is necessary. And finally, if an investigation could be done of the theoretical properties of the GMKL and its relative performance compared to SVM would be appreciated to cement the useful GMKL as a data integration technique.































\end{document}

