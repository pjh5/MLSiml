\documentclass{article}
\usepackage{courier}
\renewcommand{\ttdefault}{pcr}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{booktabs}
\setlength{\parindent}{0cm}

\begin{document}
\title{Data Integration on High-Difficulty Binary Classification}
\author{Julia Finch, Jesse Hellemn, Kentaro Hoffman, Zhe Zhang}
\maketitle


\section{Overview and Motivation}
For many fields, especially in medicine and the social sciences, it is
increasingly common for data to come from multiple disparate data sources. For
example, a sociologist might be interested in predicting future income with two
datasets, family environment and school environment. For the best analysis, all
data sources should be utilized.


A naive approach is to concatenate the sources together into one large feature
matrix. Although simple and computationally efficient, this method throws away
information about the separate sources and forces downstream processing to
treat all of the sources in the same way. Various data integration techniques
have been proposed to more cleverly and effectively combine multiple sources.
Unfortunately, most of these techniques are poorly understood or poorly tested,
and there has been no systematic evaluation of their effectiveness.


This paper evaluates Generalized Metric Kernel Learning (GMKL) over simulated
data.


\section{Data Generation}

\subsection{Criteria of Good Simulated Data}

In order to understand the behavior of the data integration techniques, we
systematically created data that was:

\begin{enumerate}
    \item the decision boundary between the two classes was known and calculable
    \item the two classes are completely separable (or can be specified to
        overlap with percentage $p$, where $p=0$ leads to no overlap and
        $p=50$\% leads to complete overlap)
    \item the decision boundary's complexity can be parametrized and controlled
    \item the reliability of each source can be specified exactly
    \item the noisyness of each source can be specified exactly
    \item \label{criteria:noise_dims} extra meaningless dimensions can be added
        to each source
\end{enumerate}

\subsection{Data Generation Models}

\subsubsection{Random Coefficient Linear Model}

A simple, common way to simulate data is to use a linear model with random
coefficients. This model generates data by:
\begin{enumerate}
    \item Specify the number of true latent variables $K$ along with the number
        of visible variables $N$
    \item Specify two distribution $D_j^0$ and $D_j^1$ of each latent variable
        $z_j$, $1 \leq j \leq K$, where $D_j^0$ is the distribution of $z_j$
        for negative classes and $D_j^1$ is the distribution of $z_j$ for
        positive classes
    \item Specify how each visible variable $x_j$ is generated from the latent
        variables $z_i$ with a formula of the form
        $$x_l = \sum_{i=1}^K \beta_i z_i + \sum_{i=1}^K\sum_{j=i}^K \beta_{i,j} z_i z_k + \text{higher-order-interactions}$$
        of linear combinations of arbitrary functions of the latent variables
    \item Specify the distribution of every $\beta$ in the above formula
    \item For every datapoint
    \begin{enumerate}
        \item Pick which class the datapoint belongs to
        \item Sample each $z_j$ from its respective distribution for this class
        \item Sample each $\beta$ from their respective distributions
        \item Generate each visible variable $x_j$ from its formula
    \end{enumerate}
\end{enumerate}

It is common to simulate "realistic" data by randomly picking coefficients of a
linear model. This model has notable shortcomings, mainly that it is not
possible to know if the 2 classes of the generated data are 1) separated by a
complex decision boundary or 2) are overlapping and unseparable. Classification
techniques can only be accurately compared to each other on non-overlapping
data. If the two classes of generated data overlap and are not separable, then
there is no theoretical classifier that can correctly the overlapped part.

\subsubsection{Feed-forward Network Model}

We simulated data with a feed-forward fully connected conditional network
(figure \ref{fig:data_generation_model.png}).


Criteria \ref{criteria:noise_dims} is more difficult than it at first seems. In
order to create a source with $N_{useful}$ useful dimensions and $N_{noisy}$
meaningless dimensions, we needed to both 1) make $N_{noisy}$ dimensions of pure
noise and 2) make $N_{useful}$ dimensions, all of which are always useful. With a
random coefficient linear model, it is impossible to verify that all $N_{useful}$
dimensions are actually useful.


\end{document}

